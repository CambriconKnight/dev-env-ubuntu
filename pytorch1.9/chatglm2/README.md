
<p align="center">
    <a href="https://gitee.com/cambriconknight/dev-env-ubuntu/tree/master/pytorch1.9/chatglm2">
        <img alt="chatglm2-logo" src="./res/chatglm2-6b.jpg" height="140" />
        <h1 align="center">ChatGLM2æ¨¡å‹ç§»æ¤æ•™ç¨‹</h1>
    </a>
</p>

**è¯¥æ•™ç¨‹ä»…ä»…ç”¨äºå­¦ä¹ ï¼Œæ‰“é€šæµç¨‹ï¼› ä¸å¯¹æ•ˆæœè´Ÿè´£ï¼Œä¸æ‰¿è¯ºå•†ç”¨ã€‚**

[TOC]

# 1. ç¯å¢ƒå‡†å¤‡

## 1.1. ç¡¬ä»¶ç¯å¢ƒ

| åç§°           | æ•°é‡      | å¤‡æ³¨                  |
| :------------ | :--------- | :------------------ |
| æœåŠ¡å™¨         | ä¸€å°       | é‡‡ç”¨å·²å®Œæˆé€‚é…çš„æœåŠ¡å™¨ï¼›PCIe Gen.4 x16 |
| MLU370-X8     | 8å¡       | X8éœ€ä½¿ç”¨æ¿å¡è‡ªå¸¦çš„8pinè¿æ¥å™¨è¿æ¥ä¸»æ¿ç”µæº |

## 1.2. è½¯ä»¶ç¯å¢ƒ

| åç§°                   | ç‰ˆæœ¬/æ–‡ä»¶                                                 | å¤‡æ³¨                                 |
| :-------------------- | :-------------------------------                         | :---------------------------------- |
| Linux OS              | Ubuntu18.04/Ubuntu20.04/CentOS7                          | å®¿ä¸»æœºæ“ä½œç³»ç»Ÿ                         |
| Docker Image          | pytorch-v1.15.0-torch1.9-ubuntu18.04-py37.tar.gz         | å®˜æ–¹å‘å¸ƒçš„ Pytorch æ¡†æ¶ Docker é•œåƒæ–‡ä»¶ |
| Driver_MLU370         | cambricon-mlu-driver-centos7-5.10.13-1.x86_64.rpm	       | ä¾å®é™…æœåŠ¡å™¨æ“ä½œç³»ç»Ÿç‰ˆæœ¬é€‰æ‹©             |
| DeepSpeed             | cndsp-0.8.0-py3-none-any.whl                             | Cambricon DeepSpeed                 |
| å·¥å…·åŒ…                 | https://github.com/CambriconKnight/dev-env-ubuntu        | [Githubåœ°å€](https://github.com/CambriconKnight/dev-env-ubuntu) |
| ChatGLM2-6B æºç        | https://github.com/THUDM/ChatGLM2-6B  | commitï¼š 3d0225f969d56c058f052f6800a21630d14a1184 |
| Transformers æºç       | https://github.com/huggingface/transformers  | v4.30.2                         |
| ChatGLM2-6B æ¨¡å‹         | https://huggingface.co/THUDM/chatglm2-6b	  | ç›´æ¥clone é€Ÿåº¦æ…¢ï¼Œå¹¶ä¸”ä¸ºä¿æŒç‰ˆæœ¬å¯¹åº”ï¼Œä¹Ÿå¯å…³æ³¨å¾®ä¿¡å…¬ä¼—å· ã€ AIKnight ã€‘, å‘é€å…³é”®å­— **chatglm2-6b** è‡ªåŠ¨è·å–ã€‚|

**ä¸‹è½½åœ°å€:**
- å‰å¾€[å¯’æ­¦çºªå¼€å‘è€…ç¤¾åŒº](https://developer.cambricon.com)æ³¨å†Œè´¦å·æŒ‰éœ€ä¸‹è½½ï¼Œ ä¹Ÿå¯åœ¨å®˜æ–¹æä¾›çš„ä¸“å±FTPè´¦æˆ·æŒ‡å®šè·¯å¾„ä¸‹è½½ã€‚
- æ–‡æ¡£: https://developer.cambricon.com/index/document/index/classid/3.html
- SDK: https://sdk.cambricon.com/download?component_name=PyTorch

**AIKnightå…¬ä¼—å·**
>![](../../res/aiknight_wechat_344.jpg)

## 1.3. ä¸‹è½½ä»“åº“
```bash
#è¿›å…¥è£¸æœºå·¥ä½œç›®å½•ï¼Œä»¥ã€/data/githubã€‘å·¥ä½œç›®å½•ä¸ºä¾‹
cd /data/github
#ä¸‹è½½ä»“åº“
git clone https://github.com/CambriconKnight/dev-env-ubuntu.git
#è¿›å…¥ã€å·¥å…·åŒ…ç›®å½•ã€‘
cd ./dev-env-ubuntu/pytorch1.9
```
## 1.4. åŠ è½½é•œåƒ

è¯·æå‰ä¸‹è½½å¥½ã€Dockeré•œåƒã€‘ï¼Œæ–¹ä¾¿ä»¥ä¸‹æ“ä½œåŠ è½½ä½¿ç”¨ã€‚

```bash
#è¿›å…¥ã€å·¥å…·åŒ…ç›®å½•ã€‘
cd ./dev-env-ubuntu/pytorch1.9
#ä¸‹è½½Dockeré•œåƒåï¼Œå¯ä»¥mvåˆ°å½“å‰dockerç›®å½•
#åŠ è½½Dockeré•œåƒ
#./load-image-dev.sh ./docker/pytorch-v1.15.0-torch1.9-ubuntu18.04-py37.tar.gz
./load-image-dev.sh ${FULLNAME_IMAGES}
```

## 1.5. å¯åŠ¨å®¹å™¨

é•œåƒåŠ è½½å®Œæˆåï¼Œè¿è¡Œè„šæœ¬ï¼Œè¿›å…¥Dockerå®¹å™¨ã€‚

```bash
#è¿›å…¥ã€å·¥å…·åŒ…ç›®å½•ã€‘
cd ./dev-env-ubuntu/pytorch1.9
#å¯åŠ¨Dockerå®¹å™¨
./run-container-dev.sh
```

# 2. æ¨¡å‹æ¨ç†
## 2.1. å®‰è£…LFS

å®‰è£… Git LFSï¼Œå®ç° Git å¯¹å¤§æ–‡ä»¶çš„æ”¯æŒ.
```bash
# è¿›åˆ°å®¹å™¨åï¼Œåˆ‡æ¢åˆ°å·¥ä½œç›®å½•
mkdir -p /workspace/chatglm2 && cd /workspace/chatglm2
apt-get update
# å®‰è£… Git LFSï¼Œå®ç° Git å¯¹å¤§æ–‡ä»¶çš„æ”¯æŒ
apt-get install git-lfs
#yum install git-lfs
# Silence all safe.directory warnings
git config --global --add safe.directory '*'
# æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤åï¼Œå¦‚æœæ˜¾ç¤ºGit LFS initializedè¯´æ˜å®‰è£…æˆåŠŸ
git lfs install
# å‡çº§numpyç‰ˆæœ¬
pip install numpy --upgrade
```
## 2.2. ä¸‹è½½ä»£ç 

ä¸‹è½½ transformers åŠ chatglm2-6b æºç åŠå¯¹åº”ç‰ˆæœ¬çš„ chatglm2-6b æ¨¡å‹ï¼ˆæ¨¡å‹è¾ƒå¤§ï¼Œä¸‹è½½æ—¶é—´æ¯”è¾ƒé•¿ï¼‰ã€‚
```bash
# è¿›åˆ°å®¹å™¨åï¼Œåˆ‡æ¢åˆ°å·¥ä½œç›®å½•
cd /workspace/chatglm2
# 1. ä¸‹è½½ transformers æºç : åŸºäº transformer æ¨¡å‹ç»“æ„æä¾›çš„é¢„è®­ç»ƒè¯­è¨€åº“
git clone -b v4.30.2 https://github.com/huggingface/transformers
# 2. ä¸‹è½½ chatglm2-6b æºç 
git clone https://github.com/THUDM/ChatGLM2-6B
cd ChatGLM2-6B && git checkout 3d0225f969d56c058f052f6800a21630d14a1184 && cd -
# 3. ä¸‹è½½ chatglm2-6b æ¨¡å‹å®ç°
##ç¬¬ä¸€ç§æ–¹å¼ï¼š ä¸æ¨èä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ã€‚ç›´æ¥ git clone å¤§æ¨¡å‹æ–‡ä»¶çš„è¯ï¼Œä¸‹è½½æ¨¡å‹æ—¶é—´è¾ƒé•¿.
# git clone https://huggingface.co/THUDM/chatglm2-6b
##ç¬¬äºŒç§æ–¹å¼ï¼š é‡‡ç”¨å¦‚ä¸‹æ–¹å¼ï¼Œ git clone å¹¶æ‰‹åŠ¨ä¸‹è½½æˆ–æ‹·è´è¿‡æ¥æ¨¡å‹ï¼Œä¼šæ›´æ–¹ä¾¿äº›ã€‚
GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/THUDM/chatglm2-6b
# æ­¤æ–¹å¼ä»…ä¸‹è½½ä¸€ä¸ªæ¨¡å‹æ ‡è¯†æ–‡ä»¶ï¼Œç„¶åä»https://huggingface.co/THUDM/chatglm2-6b/tree/mainï¼ˆæˆ–å›½å†…ç«™ç‚¹ï¼‰æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹å’Œå‚æ•°æ–‡ä»¶ï¼Œæ›¿æ¢åˆ°æœ¬åœ°çš„ chatglm2-6b ç›®å½•ä¸‹ã€‚
# å›½å†…å¯ä»¥ä»https://cloud.tsinghua.edu.cn/d/674208019e314311ab5c/ æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹å‚æ•°æ–‡ä»¶ï¼Œå¹¶å°†ä¸‹è½½çš„æ–‡ä»¶æ›¿æ¢åˆ°æœ¬åœ°çš„ chatglm2-6b ç›®å½•ä¸‹ã€‚
#cp -rvf /data/models/chatglm2-6b/pretrained_model/chatglm2-6b/pytorch_model-0000*.bin ./chatglm2-6b
#cp -rvf /data/models/chatglm2-6b/pretrained_model/chatglm2-6b/ice_text.model ./chatglm2-6b
# æ³¨æ„ï¼š å¦‚æœåç»­æ“ä½œä¸­ï¼Œæœ‰shape mismatchä¹‹ç±»æŠ¥é”™ï¼Œå¤šåŠæ˜¯æ¨¡å‹æ›´æ–°äº†ï¼Œéœ€è¦ä¸‹è½½å¯¹åº”çš„æ¨¡å‹ã€‚
##ç¬¬ä¸‰ç§æ–¹å¼(æ¨è)ï¼š ä¸ºä¿è¯ä¸ä»¥ä¸Šä»£ç å¯¹åº”çš„æ¨¡å‹ï¼Œä¹Ÿå¯é€šè¿‡å…³æ³¨å¾®ä¿¡å…¬ä¼—å· ã€AIKnightã€‘,
# å‘é€å…³é”®å­—(ä¸åŒºåˆ†å¤§å°å†™): **chatglm2-6b**, å…¬ä¼—å·ä¼šè‡ªåŠ¨å›å¤å¯¹åº”ä¸‹è½½åœ°å€.
# ä¸‹è½½å®Œæ¯•åï¼Œå¯æŠŠä¸‹è½½åçš„ã€chatglm2-6bã€‘ç›®å½•æ‹·è´åˆ°å½“å‰ç›®å½•ã€‚
cp -rvf /data/baidudisk/chatglm2-6b ./
#cp -rvf /data/models/chatglm2-6b/ ./
#mv -f /DATA_SPACE/baidudisk/chatglm2-6b ./
```

## 2.3. æ¨¡å‹é€‚é…
### 2.3.1. è‡ªåŠ¨è¿ç§»ä»£ç 

ä½¿ç”¨å·¥å…· `torch_gpu2mlu.py` ä» GPU æ¨¡å‹è„šæœ¬è¿ç§»è‡³ MLU è®¾å¤‡è¿è¡Œï¼Œè½¬æ¢åçš„æ¨¡å‹è„šæœ¬åªæ”¯æŒ MLU è®¾å¤‡è¿è¡Œã€‚è¯¥å·¥å…·å¯å¯¹æ¨¡å‹è„šæœ¬è¿›è¡Œè½¬æ¢ï¼Œå¯¹æ¨¡å‹è„šæœ¬ä¿®æ”¹ä½ç½®è¾ƒå¤šï¼Œä¼šå¯¹ä¿®æ”¹ä½ç½®è¿›è¡Œç»Ÿè®¡ï¼Œå®ç°å¼€å‘è€…å¿«é€Ÿè¿ç§»ã€‚

- åœ¨å®¹å™¨ç¯å¢ƒä¸­ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤
```bash
cd /workspace/chatglm2
#å»ºç«‹è½¯è¿æ¥
ln -s /torch/src/catch/tools/torch_gpu2mlu.py ./
#æ‰§è¡Œè½¬æ¢æ¨¡å‹è„šæœ¬, è‡ªåŠ¨ä¿®æ”¹ transformers æºç 
python torch_gpu2mlu.py -i transformers
#æ‰§è¡Œè½¬æ¢æ¨¡å‹è„šæœ¬, è‡ªåŠ¨ä¿®æ”¹  ChatGLM2-6B æºç 
python torch_gpu2mlu.py -i ChatGLM2-6B
#æ˜¾ç¤ºè½¬æ¢åçš„ä»£ç ã€‚
#ls -lh transformers transformers_mlu ChatGLM2-6B ChatGLM2-6B_mlu
ls -la
```

- è¾“å‡ºè½¬æ¢ç»“æœ
```bash
(pytorch) root@worker1:/workspace/chatglm2# python torch_gpu2mlu.py -i transformers
# Cambricon PyTorch Model Migration Report
Official PyTorch model scripts:  /workspace/chatglm2/transformers
Cambricon PyTorch model scripts:  /workspace/chatglm2/transformers_mlu
Migration Report:  /workspace/chatglm2/transformers_mlu/report.md
(pytorch) root@worker1:/workspace/chatglm2# python torch_gpu2mlu.py -i ChatGLM2-6B
# Cambricon PyTorch Model Migration Report
Official PyTorch model scripts:  /workspace/chatglm2/ChatGLM2-6B
Cambricon PyTorch model scripts:  /workspace/chatglm2/ChatGLM2-6B_mlu
Migration Report:  /workspace/chatglm2/ChatGLM2-6B_mlu/report.md
(pytorch) root@worker1:/workspace/chatglm2#
```

### 2.3.2. æ‰‹åŠ¨ä¿®æ”¹ä»£ç 

ç”±äº chatglm2-6b è¦æ±‚ä½¿ç”¨ torch >=1.10ï¼Œå…¶ä¸­æœ‰ pytorch ä¸æ”¯æŒçš„ç‰¹æ€§åŒ…æ‹¬å¦‚ä¸‹ã€‚éœ€è¦åœ¨ã€è‡ªåŠ¨è¿ç§»ä»£ç ã€‘åŸºç¡€ä¸Šå†è¿›è¡Œå¦‚ä¸‹ä¿®æ”¹ã€‚

è¿›å…¥å·¥ä½œç›®å½•ï¼Œæ‹·è´ä¿®æ”¹åçš„ä»£ç åˆ°ã€chatglm2-6bã€‘ç›®å½•ã€‚
```bash
# è¿›å…¥å·¥ä½œç›®å½•  /home/share/pytorch1.9/chatglm2/tools/modeling_chatglm.py
cd /workspace/chatglm2
cp -rvf /home/share/pytorch1.9/chatglm2/tools/modeling_chatglm.py ./chatglm2-6b
```

### 2.3.3. å®‰è£…ä¾èµ–åº“

```bash
# å®‰è£… transformers
cd /workspace/chatglm2/transformers_mlu/
pip install -e .

# å®‰è£… ChatGLM2-6B ä¾èµ–åº“
cd /workspace/chatglm2/ChatGLM2-6B_mlu
sed -i 's/torch/# torch/' requirements.txt
sed -i 's/transformers/# transformer/' requirements.txt
pip install -r requirements.txt

#ä½¿ç”¨ pip å®‰è£… sentencepiece gradio
pip install sse-starlette mdtex2html sentencepiece gradio
#pip install mdtex2html
#pip install sentencepiece
# gradioå®‰è£…æ—¶é—´é•¿ï¼Œè€å¿ƒç­‰å¾…ã€‚
#pip install gradio
```

## 2.4. æµ‹è¯•éªŒè¯
```bash
# è¿›å…¥ChatGLM2-6B_mluè·¯å¾„ï¼ˆä»¥å®é™…ä¸ºå‡†ï¼‰
cd /workspace/chatglm2/ChatGLM2-6B_mlu

# æ ¹æ®ä½¿ç”¨çš„demoï¼Œä¿®æ”¹cli_demo.pyæˆ–web_demo.pyæˆ–api.pyä¸­çš„é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„â€œTHUDM/chatglm2-6bâ€ä¸ºå®é™…è·¯å¾„ï¼Œæœ¬æ•™ç¨‹ä¸­æ­¤è·¯å¾„ä¿®æ”¹ä¸ºã€../chatglm2-6bã€‘ã€‚
#tokenizer = AutoTokenizer.from_pretrained("THUDM/chatglm2-6b", trust_remote_code=True)
#model = AutoModel.from_pretrained("THUDM/chatglm2-6b", trust_remote_code=True).half().mlu()
tokenizer = AutoTokenizer.from_pretrained("../chatglm2-6b", trust_remote_code=True)
model = AutoModel.from_pretrained("../chatglm2-6b", trust_remote_code=True).mlu()
#ä¹Ÿå¯æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œç›´æ¥æ‹·è´ä¿®æ”¹åçš„æ–‡ä»¶
cp -rvf /home/share/pytorch1.9/chatglm2/tools/cli_demo.py ./
# CLIæµ‹è¯•éªŒè¯
export MLU_VISIBLE_DEVICES=0
python cli_demo.py
#pip install sentencepiece gradio

# æˆ–python web_demo.py æˆ–python api.py
# æ³¨æ„ï¼šå¦‚ä½¿ç”¨web_demo.pyï¼Œéœ€ä¿®æ”¹demo.queue().launch(share=False, inbrowser=True)ä¸­share=Trueï¼Œå¦åˆ™æ— æ³•çœ‹åˆ°gradioåœ°å€
#cp -rvf /home/share/pytorch1.9/chatglm2/tools/web_demo.py ./
# WEBæµ‹è¯•éªŒè¯
#python web_demo.py

# APIæµ‹è¯•éªŒè¯
#cp -rvf /home/share/pytorch1.9/chatglm2/tools/api.py ./
#python api.py
```

### 2.4.1. æµ‹è¯•CLIå®ä¾‹

ä½¿ç”¨ cli_demo.pyæµ‹è¯•ã€‚

*åŠ è½½æ¯”è¾ƒæ…¢ï¼Œå¤§æ¦‚éœ€è¦10åˆ†é’Ÿï¼Œå¯è€å¿ƒç­‰å¾…ã€‚*
```bash
(pytorch) root@worker1:/workspace/chatglm2/ChatGLM2-6B_mlu# python cli_demo.py
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:08<00:00,  1.25s/it]
æ¬¢è¿ä½¿ç”¨ ChatGLM2-6B æ¨¡å‹ï¼Œè¾“å…¥å†…å®¹å³å¯è¿›è¡Œå¯¹è¯ï¼Œclear æ¸…ç©ºå¯¹è¯å†å²ï¼Œstop ç»ˆæ­¢ç¨‹åº

ç”¨æˆ·ï¼šä½ å¥½

ChatGLMï¼š/workspace/chatglm2/transformers_mlu/src/transformers/tokenization_utils_base.py:773: UserWarning:  MLU operators dont support 64-bit calculation. so the 64 bit data will be forcibly converted to 32-bit for calculation.  (Triggered internally at  /torch/catch/torch_mlu/csrc/aten/util/tensor_util.cpp:153.)
  self.data = {k: v.to(device=device) for k, v in self.data.items()}
ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM2-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚

ç”¨æˆ·ï¼šä¸­å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œ?

ChatGLMï¼šä¸­å›½çš„é¦–éƒ½æ˜¯åŒ—äº¬å¸‚ã€‚

ç”¨æˆ·ï¼šè¯¦ç»†ä»‹ç»ä¸‹è¿™ä¸ªåŸå¸‚å§

ChatGLMï¼šåŒ—äº¬ï¼Œç®€ç§°â€œäº¬â€ï¼Œæ˜¯ä¸­å›½çš„é¦–éƒ½ï¼Œæ˜¯å…¨å›½çš„æ”¿æ²»ä¸­å¿ƒã€æ–‡åŒ–ä¸­å¿ƒï¼Œæ˜¯ä¸–ç•Œè‘—åå¤éƒ½å’Œç°ä»£åŒ–å›½é™…åŸå¸‚ã€‚

åŒ—äº¬åœ°å¤„ä¸­å›½åŒ—éƒ¨ã€ååŒ—å¹³åŸåŒ—éƒ¨ï¼Œä¸œä¸å¤©æ´¥æ¯—è¿ï¼Œå…¶ä½™å‡ä¸æ²³åŒ—ç›¸é‚»ï¼Œä¸­å¿ƒä½ç½®ä¸œç» 116Â°20â€²ã€åŒ—çº¬ 39Â°54â€²ï¼Œæ˜¯ä¸–ç•Œè‘—åå¤éƒ½å’Œç°ä»£åŒ–å›½é™…åŸå¸‚ï¼Œ

åŒ—äº¬ä¸­å›½å†å²æ–‡åŒ–ååŸå’Œå¤éƒ½ä¹‹ä¸€ï¼Œæ‹¥æœ‰è®¸å¤šå†å²åèƒœå’Œç°ä»£åŒ–å»ºç­‘ï¼Œæ˜¯ä¸­å›½ä¹ƒè‡³ä¸–ç•Œä¸Šæœ€å…·ä»£è¡¨æ€§å’Œå¸å¼•åŠ›çš„å¤§éƒ½å¸‚ä¹‹ä¸€ã€‚

åŒ—äº¬æ˜¯ä¸€ä¸ªæ‹¥æœ‰æ‚ ä¹…å†å²å’Œä¸°å¯Œæ–‡åŒ–çš„ååŸï¼Œæ›¾ç»æ˜¯æ˜ã€æ¸…ä¸¤æœçš„å›½éƒ½ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„å†å²é—äº§ï¼Œå¦‚ç´«ç¦åŸã€é•¿åŸç­‰ã€‚æ­¤å¤–ï¼ŒåŒ—äº¬è¿˜æ‹¥æœ‰è®¸å¤šç°ä»£åŒ–å»ºç­‘å’Œè®¾æ–½ï¼Œå¦‚é¸Ÿå·¢ã€æ°´ç«‹æ–¹ç­‰æ ‡å¿—æ€§å»ºç­‘ï¼Œä»¥åŠé«˜é€Ÿå…¬è·¯ã€é«˜é“ã€æœºåœºç­‰äº¤é€šè®¾æ–½ã€‚

åŒ—äº¬æ˜¯ä¸€ä¸ªå……æ»¡æ´»åŠ›å’Œå¸å¼•åŠ›çš„åŸå¸‚ï¼Œå¸å¼•äº†æ¥è‡ªä¸–ç•Œå„åœ°çš„äººä»¬å‰æ¥æ¢ç´¢ã€è§‚å…‰ã€å­¦ä¹ ã€äº¤æµã€‚

ç”¨æˆ·ï¼šé€€ä¸‹å§

ChatGLMï¼šå¥½çš„ï¼Œå¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–é—®é¢˜ï¼Œè¯·éšæ—¶æå‡ºã€‚

ç”¨æˆ·ï¼šstop
(pytorch) root@worker1:/workspace/chatglm2/ChatGLM2-6B_mlu#
```

### 2.4.2. æµ‹è¯•WEBå®ä¾‹

ä½¿ç”¨ web_demo.pyæµ‹è¯• ï¼Œéœ€ä¿®æ”¹ demo.queue().launch(share=False, inbrowser=True) ä¸­ share=True ï¼Œå¦åˆ™æ— æ³•çœ‹åˆ° gradio åœ°å€ã€‚

*åŠ è½½æ¯”è¾ƒæ…¢ï¼Œå¤§æ¦‚éœ€è¦10åˆ†é’Ÿï¼Œå¯è€å¿ƒç­‰å¾…ã€‚*

```bash
(pytorch) root@worker1:/workspace/chatglm2/ChatGLM2-6B_mlu# python web_demo.py
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:08<00:00,  1.26s/it]
Running on local URL:  http://127.0.0.1:7000
Running on public URL: https://d770ab15d67f55c617.gradio.live

This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)
```

**Webå±•ç¤ºæ•ˆæœ**

*å¾…è¡¥å……*
